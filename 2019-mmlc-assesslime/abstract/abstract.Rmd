---
title: "MMLC Abstract"
author: "Katherine Goode"
date: "3/29/2019"
output: html_document
---

#### Title

Visual Diagnostics of a Model Explainer: Tools for the Assessment of LIME Explanations from Random Forests

#### Abstract

Random forests are known for their accurate predictive abilities, but they are a part of the family of machine learning models that lack interpretability. A technique called LIME was developed to provide local interpretations for predictive models. The technique fits a ridge regression model to binary encoded perturbations created from the observed data weighted by proximity to the  prediction of interest. The predicted values associated with the perturbations computed using the complex model are used as the response variable in the regression. The coefficients from the linear model are then used to determine the influential variables. We have developed some visualizations and other diagnostic tools to assess the explanations produced by LIME from a random forest. In particular, we consider how well the simple model fit by LIME captures the random forest model and how the results from LIME vary based on different algorithm input options. To demonstrate these tools, we apply LIME to a random forest fit to a forensics bullet matching dataset using the lime R package and apply our methods to diagnose the LIME explanations.

#### Key Words

LIME, random forest, black box model, interpretability, diagnostics

